% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Shannon_Index.R
\name{Shannon_Index}
\alias{Shannon_Index}
\title{Shannon Entropy Index.}
\usage{
Shannon_Index(x, base = exp(1), ...)
}
\arguments{
\item{x}{a contingency table or a vector. If a vector, passed to \code{\link[base]{table}}.}

\item{base}{base of the logarithm to be used. Default is exp(1), natural.
Base 2 and base 10 are also common.}

\item{...}{if x is a vector, further arguments to be passed on to \code{\link[base]{table}}.}
}
\value{
a numeric value.
}
\description{
Calculates the Shannon's entropy index as a measure of diversity within a sample.
}
\details{
The Shannon entropy index uses information theory to measure the uncertainty of a random variable.
As the index increases, there is greater uncertainty that a random observation is from a particular group.
Commonly used in ecological contexts, the utility of the index can extend to measure the heterogeneity, or diversity, of human populations.
The Shannon index uses the formula \eqn{H = -\sum_{k=1}^{K} \pi_k log\left(\pi_k\right)}
 where \eqn{\pi} is the proportion of group *k* within a population.
}
\examples{
vec <- rep(LETTERS'\['1:7], times = c(50,30,20,10,10,5,5))
Shannon_Index(tab)

tab <- table(vec, useNA = "always")
Shannon_Index(vec, useNA = "always")

}
